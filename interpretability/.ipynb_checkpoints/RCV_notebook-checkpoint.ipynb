{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Concep Vectors for Bidirectional Relevance Scores in Histopathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts/keras_vis_rcv/')\n",
    "import rcv_utils\n",
    "import os\n",
    "import numpy as np\n",
    "from camnet import Camnet\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import h5py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first thing, we load ResNet101 finetuned to classify between tumor and non-tumor patches. \n",
    "The network has been trained on 224x224 patches randomly sampled from the highest resolution level of the WSIs in Camelyon16 (hopefully) and Camelyon17. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Truncated file: eof = 30797497, sblock->base_addr = 0, stored_eof = 171968624)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-607005796fe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#settings = functions.parseTrainingOptions(CONFIG_FILE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#bc_model = models.getModel(settings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/0528-1559/tumor_classifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/mara.graziani/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   2636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2640\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mara.graziani/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mara.graziani/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Truncated file: eof = 30797497, sblock->base_addr = 0, stored_eof = 171968624)"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE='./models/default_config.cfg'\n",
    "camnet = Camnet(CONFIG_FILE)\n",
    "bc_model=camnet.get_model()\n",
    "bc_model.load_weights('./models/0528-1559/tumor_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset used to extract concepts about the nuclei morphology and texture. The DATASETNAME for nuclei segmentation contains 6 Breast Cancer WSIs. From them we sample 300 random patches and we compute statistics on the nuclei morphology and texture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches, masks, nuclei, stats = tcav_utils.get_norm_patches(path='./datasets/training/'+str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nuclei morphology statistics\n",
    "nuclei_morph = tcav_utils.nuclei_morphology(stats)\n",
    "# Nuclei texture statistics\n",
    "nuclei_text = tcav_utils.nuclei_texture(patches, nuclei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the cancer probability for each one of the concept-patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = np.float64(patches)\n",
    "inputs = models.standardPreprocess(inputs)\n",
    "predictions = bc_model.predict(inputs[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions.reshape((50,))\n",
    "os.mkdir('results/')\n",
    "np.save('results/predictions', predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first show the correlation between some characteristics of the nuclei and the network predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correlation analysis and p-values\n",
    "def corr_analysis(feature, pred):\n",
    "    return scipy.stats.pearsonr(np.array(feature), np.array(pred))\n",
    "# Correlation analysis of morphology statistics\n",
    "print 'area: ', corr_analysis(np.array(nuclei_morph['area'][:50]).reshape((50,)), predictions)\n",
    "print 'perimeter: ', corr_analysis(nuclei_morph['perimeter'][:50], predictions)\n",
    "print 'eccentricity: ', corr_analysis(nuclei_morph['eccentricity'][:50], predictions)\n",
    "print 'mjaxis: ', corr_analysis(nuclei_morph['mjaxis'][:50], predictions)\n",
    "print 'euler: ', corr_analysis(nuclei_morph['euler'][:50], predictions)\n",
    "# Correlation analysis of texture features\n",
    "print 'contrast: ', corr_analysis(nuclei_text['contrast'][:50], predictions)\n",
    "print 'ASM: ', corr_analysis(nuclei_text['ASM'][:50], predictions)\n",
    "print 'correlation: ', corr_analysis(nuclei_text['correlation'][:50], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast and dissimilarity seem to be correlated with the predictions, as well. We will analyse these concepts.\n",
    "NB. Correlation seems negatively correlated with the prediction, so we could potentially think of it as a Reverse Concept for classification, which is indicative of the class non-cancer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ResNet features for concepts. \n",
    "We will now extract high-dimensional feature representations of the patches with a forward pass. \n",
    "These features will then be used to learn the concept vectors. \n",
    "We analyse three different levels in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Linear Regression in the activation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = ['conv1',\n",
    "          'res2a',\n",
    "          'res2b',\n",
    "          'res2c',\n",
    "          'res3a', # quite early in the network\n",
    "          'res3b1',\n",
    "          'res3b2',\n",
    "          'res3b3',\n",
    "          'res4a', # middle\n",
    "          'res4b1',\n",
    "          'res4b2',\n",
    "          'res4b3',\n",
    "          'res4b4',\n",
    "          'res4b5',\n",
    "          'res4b6',\n",
    "          'res4b7',\n",
    "          'res4b8',\n",
    "          'res4b9',\n",
    "          'res4b10',\n",
    "          'res4b15',\n",
    "          'res4b16',\n",
    "          'res4b17',\n",
    "          'res4b18',\n",
    "          'res4b19',\n",
    "          'res4b20',\n",
    "          'res5a'  # closer to the last layers\n",
    "         ]\n",
    "l = 'res4a'\n",
    "concepts=['perimeter',\n",
    " 'area',\n",
    " 'mjaxis',\n",
    " 'eccentricity',\n",
    " 'euler',\n",
    " 'contrast', \n",
    " 'ASM',\n",
    " 'correlation',]\n",
    "max_rep = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repetition in range(0, max_rep):\n",
    "    tr_set=tcav_utils.get_cv_training_set('./datasets/breast_nuclei/Tissue Images/', repetition)\n",
    "    patches, masks, nuclei, stats = tcav_utils.get_norm_patches(path='./datasets/training/'+str(repetition))\n",
    "    nuclei_morph = tcav_utils.nuclei_morphology(stats)\n",
    "    # Nuclei texture statistics\n",
    "    nuclei_text = tcav_utils.nuclei_texture(patches, nuclei)\n",
    "    inputs = np.float64(patches)\n",
    "    inputs = models.standardPreprocess(inputs)\n",
    "    get_layer_output = K.function([bc_model.layers[0].input],\n",
    "                              [bc_model.get_layer(l).output])\n",
    "    feats = get_layer_output([inputs])\n",
    "    np.save('./rcv/phis/'+str(repetition)+'_concepts_phis_'+l, np.asarray(feats[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_regression(inputs, y, n_splits=2, n_repeats=1, random_state=12883823, verbose=0):\n",
    "    scores=[]\n",
    "    max_score = 0\n",
    "    direction = None\n",
    "    rkf = sklearn.model_selection.RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "    counter = 0\n",
    "    for train, test in rkf.split(inputs):\n",
    "        if verbose:\n",
    "            print 'N. ', counter, '..'\n",
    "        reg = sklearn.linear_model.LinearRegression()\n",
    "        reg.fit(inputs[train], y[train])\n",
    "        trial_score = reg.score(inputs[test], y[test])\n",
    "        scores.append(trial_score)\n",
    "        if trial_score > max_score:\n",
    "            direction = reg.coef_\n",
    "        if verbose:\n",
    "            print trial_score\n",
    "        counter += 1\n",
    "    if verbose:\n",
    "        print np.mean(scores)\n",
    "    return np.mean(scores), direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats=[]\n",
    "for repetition in range(max_rep):\n",
    "    patches, masks, nuclei, stats = tcav_utils.get_norm_patches(path='./datasets/training/'+str(repetition))\n",
    "    nuclei_morph = tcav_utils.nuclei_morphology(stats)\n",
    "    nuclei_text = tcav_utils.nuclei_texture(patches, nuclei)\n",
    "    feats=np.load('./rcv/phis/'+str(repetition)+'_concepts_phis_res4a.npy')\n",
    "    X=(np.asarray([x.ravel() for x in feats], dtype=np.float64))\n",
    "    for c in concepts[:-3]:\n",
    "        reg_score, cv = solve_regression(X, np.asarray(nuclei_morph[c]))\n",
    "        np.save('./rcv/reg_score_'+c+'_'+str(repetition)+'.npy', reg_score)\n",
    "        np.save('./rcv/rcv_'+c+'_'+str(repetition)+'.npy', cv)\n",
    "    for c in concepts[-3:]:\n",
    "        reg_score, cv = solve_regression(X, np.asarray(nuclei_text[c]))\n",
    "        np.save('./rcv/reg_score_'+c+'_'+str(repetition)+'.npy', reg_score)\n",
    "        np.save('./rcv/rcv_'+c+'_'+str(repetition)+'.npy', cv)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Sensitivity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute sensitivity scores as the directional derivative of the test inputs on the RCV in the activation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the test inputs\n",
    "PWD = '/mnt/nas2/results/IntermediateResults/Camelyon/all500'\n",
    "h5file = 'patches.hdf5'\n",
    "db = h5py.File(os.path.join(PWD, h5file), 'r')\n",
    "os.path.join(PWD, h5file)\n",
    "def print_info(name, obj):\n",
    "    print name \n",
    "db.visititems(print_info)\n",
    "tumor_patches = db['all_tumor_patches']\n",
    "normalizer = tcav_utils.get_normalizer()\n",
    "normalised_tumor_patches = np.array([tcav_utils.normalize_patch(np.uint8(patch), normalizer) for patch in tumor_patches[0:3000:10]])\n",
    "test_inputs = np.float64(normalised_tumor_patches)\n",
    "test_inputs = models.standardPreprocess(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in concepts[5:]:\n",
    "    for i in range(0, 30):\n",
    "        print concept\n",
    "        rcv = np.load('./rcv/rcv_'+concept+'_'+str(i)+'.npy')\n",
    "        rcv /= np.linalg.norm(rcv)\n",
    "        repetition = 0\n",
    "        for p in range(len(test_inputs[:50])):\n",
    "            nnn = tcav_utils.compute_tcav(bc_model,-1,0, np.expand_dims(test_inputs[p], axis=0), wrt_tensor=bc_model.get_layer('res4a').output)\n",
    "            flattened_derivative=nnn.ravel()\n",
    "            score = np.multiply(-1, np.dot(flattened_derivative, rcv))\n",
    "            filet=open('tcav_'+concept+'_'+str(i)+'.txt', 'a')\n",
    "            filet.write(str(repetition)+','+str(score)+'\\n')\n",
    "            filet.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute TCAV and Br scores and check statistical relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scores(scores, legend, legend_entry, color):\n",
    "    mu = np.mean(scores)\n",
    "    variance = np.std(scores)\n",
    "    sigma = math.sqrt(variance)\n",
    "\n",
    "    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "    plt.plot(x,mlab.normpdf(x, mu, sigma), color=color)\n",
    "    plt.scatter([mu,mu,mu,mu], [0,0.25,0.5,0.75],marker='*',c=color, s=3)\n",
    "    legend.append(legend_entry)\n",
    "    return mu, variance, sigma, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Random TCAVs'\n",
    "#print 0.06\n",
    "N=50.0\n",
    "mmax=30\n",
    "TCAVs=np.zeros((mmax,))\n",
    "Brs=np.zeros((mmax,))\n",
    "VBrs=np.zeros((mmax,))\n",
    "real_TCAVs=np.ones((mmax,))\n",
    "real_Brs=np.zeros((mmax,))\n",
    "\n",
    "#['area', 'contrast','eccentricity','ASM', 'correlation','euler']\n",
    "for concept in concepts:\n",
    "    TCAVs=np.zeros((mmax,))\n",
    "    for i in range(0,10):\n",
    "        df=[]\n",
    "        df=pd.read_csv('./'+'tcavrandom_'+str(i)+'.txt', header=None)\n",
    "        TCAV = np.sum(np.sign(np.array(df[1]))>0) / np.float(len(np.array(df[1])))\n",
    "        R = 0\n",
    "        Br = R * np.mean(np.array(df[1])) / np.std(np.array(df[1]))\n",
    "        VBr = R * np.mean(np.array(df[1]))\n",
    "        TCAVs[i]=TCAV\n",
    "        Brs[i]=Br\n",
    "        VBrs[i]=VBr\n",
    "        #print TCAV\n",
    "    for i in range(0,mmax):\n",
    "        if os.path.exists('./'+'tcav_'+concept+'_'+str(i)+'.txt'):\n",
    "            df=[]\n",
    "            df=pd.read_csv('./'+'tcav_'+concept+'_'+str(i)+'.txt', header=None)\n",
    "            #print './'+'tcavrandom_'+str(i)+'.txt'\n",
    "            TCAV = np.sum(np.sign(np.array(df[1]))>0) /np.float(len(np.array(df[1])))\n",
    "            R = np.load('./rcv/reg_score_'+concept+'_'+str(i)+'.npy')\n",
    "            Br = R * np.mean(np.array(df[1])) / np.std(np.array(df[1]))\n",
    "            VBr = R * np.mean(np.array(df[1]))\n",
    "            real_TCAVs[i]=TCAV\n",
    "            real_Brs[i]=Br\n",
    "            real_VBrs[i]=VBr\n",
    "                \n",
    "    plt.figure() \n",
    "    leg =[]\n",
    "    print TCAVs\n",
    "\n",
    "    random_mu, random_variance, random_sigma, leg =  plot_scores(TCAVs, leg, 'random_TCAV', 'orange')\n",
    "    mu, variance, sigma, leg =  plot_scores(real_TCAVs, leg, 'TCAV', 'green')\n",
    "    br_mu, br_variange, br_sigma, leg =  plot_scores(real_Brs, leg, 'Br', 'red')\n",
    "\n",
    "    plt.legend(leg[:4])\n",
    "    plt.title(concept)\n",
    "    plt.show()\n",
    "    \n",
    "    print 'random_TCAV', TCAVs, random_mu, random_variance, random_sigma\n",
    "    print 'TCAV', real_TCAVs, mu, variance, sigma  \n",
    "    \n",
    "    print 'T-test\" ', (mu - .5) * np.math.sqrt(len(real_TCAVs))/ (variance)\n",
    "\n",
    "    print 'Br', br_mu, br_variange, br_sigma\n",
    "    \n",
    "    print 'Br T-test\" ', (br_mu - 0) * np.math.sqrt(len(real_Brs))/ (br_variange)\n",
    "    \n",
    "    #print 'VBr', vbr_mu, vbr_variange, vbr_sigma\n",
    "    \n",
    "    #print 'TCAV', real_TCAVs, tmu, tsigma \n",
    "    #print 'Br', real_Brs, rmu, rsigma\n",
    "    #print 'VBr', real_VBrs, mu, sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
